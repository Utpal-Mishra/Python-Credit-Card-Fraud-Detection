{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreditCardFraudDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jgiZAKP9yUjf",
        "cZJ-h-LSye6I",
        "XZF_bu1byp_7",
        "JhNKDyAO1MiO",
        "ni0WiBNW1VdB",
        "S7qiblRq15S8",
        "zFcVKYY7V715",
        "Ltwo4bpdfUJB",
        "nZyd_Hfz2oLo",
        "Mzr01v1ThHp3",
        "MNRXrNXEH6wv",
        "o2NV_zuNP3vE",
        "HWm6WYhm4Fgj"
      ],
      "mount_file_id": "1qrqGvtw7q2n9KAsxJJsynyOQQJFyub0S",
      "authorship_tag": "ABX9TyPXiEP5YlasYJIvcTnUpjln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utpal-Mishra/Python-Credit-Card-Fraud-Detection/blob/main/CreditCardFraudDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks43SbQdy4PG"
      },
      "source": [
        "#INSTALLING PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opX7tM8zvePJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "dfe04f55-8fab-4807-d75f-d059a507a6c0"
      },
      "source": [
        "!pip install --upgrade keras\n",
        "!pip install -q tensorflow==2.0beta1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWc9WHyryF8w"
      },
      "source": [
        "#LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDVbe1u4wkpq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zll5E-oEyKZC"
      },
      "source": [
        "#IMPORTING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFd0sGgNIlUb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cc781f9-464a-45f6-a2df-2e101206bc26"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciXzTV1lVO4D"
      },
      "source": [
        "path = '/content/drive/My Drive/CreditCardFraud/creditcard.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSeAqjEAwmk4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "ac4f255d-cedf-4529-a217-c3a461591efc"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470400</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125894</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624502</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108301</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095922</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798279</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0     0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1     0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2     1 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3     1 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4     2 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpUbv4CyOu8"
      },
      "source": [
        "#DATA VISUALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WANwS5T5w1HM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "147fa591-530e-465d-eb2a-dfe4e0494dfc"
      },
      "source": [
        "print(df.shape)\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(284807, 31)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>-1.193650e-11</td>\n",
              "      <td>-8.321435e-11</td>\n",
              "      <td>-1.193722e-10</td>\n",
              "      <td>-5.758218e-11</td>\n",
              "      <td>-8.075736e-12</td>\n",
              "      <td>-4.880404e-11</td>\n",
              "      <td>1.685322e-11</td>\n",
              "      <td>6.249845e-11</td>\n",
              "      <td>1.551921e-10</td>\n",
              "      <td>2.598242e-11</td>\n",
              "      <td>2.247260e-11</td>\n",
              "      <td>-2.071656e-11</td>\n",
              "      <td>-3.721897e-11</td>\n",
              "      <td>-1.148146e-10</td>\n",
              "      <td>-1.278054e-10</td>\n",
              "      <td>-3.159957e-12</td>\n",
              "      <td>-4.178273e-11</td>\n",
              "      <td>3.581405e-11</td>\n",
              "      <td>-5.723168e-11</td>\n",
              "      <td>5.372069e-11</td>\n",
              "      <td>1.860924e-11</td>\n",
              "      <td>4.880475e-11</td>\n",
              "      <td>-2.071527e-11</td>\n",
              "      <td>2.703579e-11</td>\n",
              "      <td>8.286263e-11</td>\n",
              "      <td>-4.880476e-11</td>\n",
              "      <td>9.128964e-12</td>\n",
              "      <td>5.617856e-12</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>1.020713e+00</td>\n",
              "      <td>9.992014e-01</td>\n",
              "      <td>9.952742e-01</td>\n",
              "      <td>9.585956e-01</td>\n",
              "      <td>9.153160e-01</td>\n",
              "      <td>8.762529e-01</td>\n",
              "      <td>8.493371e-01</td>\n",
              "      <td>8.381762e-01</td>\n",
              "      <td>8.140405e-01</td>\n",
              "      <td>7.709250e-01</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>-4.797473e+00</td>\n",
              "      <td>-1.868371e+01</td>\n",
              "      <td>-5.791881e+00</td>\n",
              "      <td>-1.921433e+01</td>\n",
              "      <td>-4.498945e+00</td>\n",
              "      <td>-1.412985e+01</td>\n",
              "      <td>-2.516280e+01</td>\n",
              "      <td>-9.498746e+00</td>\n",
              "      <td>-7.213527e+00</td>\n",
              "      <td>-5.449772e+01</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203733e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915970e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086298e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354258e-01</td>\n",
              "      <td>-7.624942e-01</td>\n",
              "      <td>-4.055715e-01</td>\n",
              "      <td>-6.485393e-01</td>\n",
              "      <td>-4.255740e-01</td>\n",
              "      <td>-5.828843e-01</td>\n",
              "      <td>-4.680368e-01</td>\n",
              "      <td>-4.837483e-01</td>\n",
              "      <td>-4.988498e-01</td>\n",
              "      <td>-4.562989e-01</td>\n",
              "      <td>-2.117214e-01</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545862e-01</td>\n",
              "      <td>-3.171450e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083955e-02</td>\n",
              "      <td>-5.295980e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548560e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984650e-02</td>\n",
              "      <td>-5.433580e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010310e-02</td>\n",
              "      <td>2.235800e-02</td>\n",
              "      <td>-5.142870e-02</td>\n",
              "      <td>-9.291740e-02</td>\n",
              "      <td>-3.275740e-02</td>\n",
              "      <td>1.400326e-01</td>\n",
              "      <td>-1.356810e-02</td>\n",
              "      <td>5.060130e-02</td>\n",
              "      <td>4.807150e-02</td>\n",
              "      <td>6.641330e-02</td>\n",
              "      <td>-6.567580e-02</td>\n",
              "      <td>-3.636300e-03</td>\n",
              "      <td>3.734800e-03</td>\n",
              "      <td>-6.248110e-02</td>\n",
              "      <td>-2.945020e-02</td>\n",
              "      <td>6.781900e-03</td>\n",
              "      <td>-1.119290e-02</td>\n",
              "      <td>4.097610e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213910e-02</td>\n",
              "      <td>1.342100e-03</td>\n",
              "      <td>1.124380e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027195e+00</td>\n",
              "      <td>7.433412e-01</td>\n",
              "      <td>6.119265e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971391e-01</td>\n",
              "      <td>4.539235e-01</td>\n",
              "      <td>7.395934e-01</td>\n",
              "      <td>6.182380e-01</td>\n",
              "      <td>6.625049e-01</td>\n",
              "      <td>4.931498e-01</td>\n",
              "      <td>6.488208e-01</td>\n",
              "      <td>5.232963e-01</td>\n",
              "      <td>3.996750e-01</td>\n",
              "      <td>5.008067e-01</td>\n",
              "      <td>4.589493e-01</td>\n",
              "      <td>1.330408e-01</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104515e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>1.201891e+01</td>\n",
              "      <td>7.848392e+00</td>\n",
              "      <td>7.126883e+00</td>\n",
              "      <td>1.052677e+01</td>\n",
              "      <td>8.877742e+00</td>\n",
              "      <td>1.731511e+01</td>\n",
              "      <td>9.253526e+00</td>\n",
              "      <td>5.041069e+00</td>\n",
              "      <td>5.591971e+00</td>\n",
              "      <td>3.942090e+01</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1  ...         Amount          Class\n",
              "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
              "mean    94813.859575 -1.193650e-11  ...      88.349619       0.001727\n",
              "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
              "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
              "25%     54201.500000 -9.203733e-01  ...       5.600000       0.000000\n",
              "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
              "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
              "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNnZcHnZDIBr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c01f2ea-e301-41bc-8606-60b5bf1f00e0"
      },
      "source": [
        "df.hist(figsize = (12,10), bins=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f78f8aa8c50>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f89f9ef0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f89be198>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f89f1400>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f89a3668>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f89578d0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f78f890cb38>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f88bdd68>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f88bddd8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f88322b0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f8864518>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f8818780>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f78f87cc9e8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f877cc50>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f87b1eb8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f86f3160>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f87263c8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f86d7630>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f78f868b898>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f8640b00>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f85f3d68>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f8627fd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f85e7278>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f859a4e0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f78f854c748>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f84ff9b0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f8531c18>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f84e9e80>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f84a7128>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f845b390>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f78f84121d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f83c1550>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f83728d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f83a6c50>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f8359fd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f78f8317390>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A8Cz0VmxToC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ec9576b6-6562-4c9a-d0e7-32e99fc295a8"
      },
      "source": [
        "df['Class'].value_counts()\n",
        "\n",
        "#print(data.groupby('Class').size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_yckp29xTqE"
      },
      "source": [
        "#data.plot(kind='density', subplots=True, layout=(5,7), sharex=False, legend=True, fontsize=1)\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZe7frLpxTzO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "fbd41132-d41b-46e6-88a6-d1c00bf9cd20"
      },
      "source": [
        "from matplotlib import cm as cm\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "cmap = cm.get_cmap('jet', 30)\n",
        "cax = ax1.imshow(df.corr(), interpolation=\"none\", cmap=cmap)\n",
        "ax1.grid(True)\n",
        "plt.title('CreditCard Fraud Attributes Correlation')\n",
        "# Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
        "fig.colorbar(cax, ticks=[.75,.8,.85,.90,.95,1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcmADmiAIvi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "a4559dc8-430f-490c-ca0d-440c630c0ab2"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "corr = df.corr()\n",
        "ax = sns.heatmap(corr, vmin =- 1, vmax = 1, center = 0, \n",
        "                  cmap = sns.diverging_palette(20, 220, n=200),\n",
        "                  square = True)\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation = 45,\n",
        "    horizontalalignment = 'right'\n",
        ");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgiZAKP9yUjf"
      },
      "source": [
        "#DATA SPLITTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heORM8uPcqF8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6ddeb671-6615-422e-8011-a43db446690d"
      },
      "source": [
        "data  = pd.concat([df[:10000],df[40000:50000]])\n",
        "data['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    19918\n",
              "1       82\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmcNojwbxT3E"
      },
      "source": [
        "Y = data['Class'].values\n",
        "X = data.drop('Class', axis=1).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zdJM5bICdao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fb9ea03-caf5-43f4-9c3c-4b078342c0fb"
      },
      "source": [
        "print(\"X_train.shape: \",X_train.shape, \"X_test.shape: \",X_test.shape,\"Y_train.shape: \", Y_train.shape, \"Y_test.shape: \",Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape:  (16000, 30) X_test.shape:  (4000, 30) Y_train.shape:  (16000,) Y_test.shape:  (4000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZJ-h-LSye6I"
      },
      "source": [
        "#ENSEMBLE MODELLING USING CROSS VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5KMllIxxT5o"
      },
      "source": [
        "models_list = []\n",
        "models_list.append(('CART', DecisionTreeClassifier()))\n",
        "models_list.append(('SVM', SVC())) \n",
        "models_list.append(('NB', GaussianNB()))\n",
        "models_list.append(('KNN', KNeighborsClassifier()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wS-9xSgxTxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "62e3291d-7a75-48a4-d542-49e4070ab283"
      },
      "source": [
        "num_folds = 10\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "for name, model in models_list:\n",
        "    kfold = KFold(n_splits = num_folds)\n",
        "    start = time.time()\n",
        "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring = 'accuracy')\n",
        "    end = time.time()\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    print( \"%s: %f (%f) (run time: %f)\" % (name, cv_results.mean(), cv_results.std(), end-start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CART: 0.999250 (0.000673) (run time: 3.050822)\n",
            "SVM: 0.996063 (0.001342) (run time: 2.303929)\n",
            "NB: 0.989688 (0.002742) (run time: 0.104972)\n",
            "KNN: 0.996188 (0.001324) (run time: 1.262284)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNeiWBJyxTvd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "ffce38ce-11bb-4eab-e8bb-d5d49ced9808"
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.suptitle('Performance Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAdCUlEQVR4nO3df7TVdZ3v8eerI/5KUJCTJSC60mY4Q4S2U2sq0MkEnVKprlJWdilaTdhMxUwarpEoLtnYj2tZLWbFLaZCm1oVc5cFXYUFXHWuh1ICSQZ/BWh1lGPmrwR83z++n6NftuecvQ9szt6Hz+ux1nex9+fz+X7P5/PlnO9rfz/f795bEYGZmeXnJc3ugJmZNYcDwMwsUw4AM7NMOQDMzDLlADAzy5QDwMwsUw4AazhJx0laI+lPkr7Y7P5Y/yS9R9LKZvfDBp8DwACQ9ICkpyU9Ien3kr4t6ah93Nxs4BFgRER8soHdbGmS3i2pM+3DhyX9TNIbm92vWiLiexHx1mb3wwafA8DK3hYRRwGnARXgqoGsrMJLgPHA3bEP7zKUdMhA12kFkj4BfAX4H8BxwAnA14ELmtmvWobq/rYGiQgvXgAeAN5Sev4vwP9Oj88EbgUeA+4CppbarQYWAv8XeBr4LrALeBZ4AngLcBjFwfGhtHwFOCytPxXYDnwK+B3wb8B84N/Ttv4E/Bp4FXAl8AdgG/DWUh8+AGxObe8DPlyq69n+J9O6DwMfKNUfAXwReBD4I7AOOKLWuKv23dFprO/qZ//Wsw/+qdTHC4HzgC3ATuDTpW3NB34I3JjG/EvgNaX6K4B7U93dwEWlusvS/9WXgUeBz6Wydaleqe4PwONp308sjXMp0JX211XAS0rbXQdcC3QD9wPTm/177aXG332zO+ClNRZKAQCMAzYBnwXGpAPFeRRnjOek5+2p7Wrgt8BfAYcAw4BvA58rbXsBcDvwMqA9HVQ/m+qmAruBa9JB8oh0gHsGODdtc2k6oMxL2/8QcH9p++cDr0wHrynAU8BpVdtfkNY9L9WPTPXXpzGMAdqAN6R+9Dvuqn03Lf2MQ/rZv/Xsg38uja8L+D4wPO3bp4GTUvv5FCH7ztR+bto/w1L9u4DjU78vBp4EXpHqLks/6/K0b49g7wA4F1gPHJP254TSukuBn6Y+nUgRTrNK292V+t4GfIQi6NTs320v/fzdN7sDXlpjoQiAJyhe7T5IMX1xBMUr83+rarsCeH96vBpYUFX/bfYOgHuB80rPzwUeSI+nUpwtHF6qnw/8ovT8balvben5cCCAY/oYy0+Avy9t/+nywZni1e2Z6QD5NKVXz6U2/Y67qvw9wO9q7N9a++DpXsZ3Rqn9euDC0v65vVT3Eoqzhjf18bPvBC5Ijy8DfltVXw6As9OB/UzSq/tU3pb+nzpKZR8GVpe2sbVUd2Qaw8ub/bvtpe/F1wCs7MKIOCYixkfE30XE0xTz+e+S9FjPArwReEVpvW01tns8Raj0eDCV9eiKiGeq1vl96fHTwCMRsaf0HOAoAEnTJd0uaWfq33nA6NL6j0bE7tLzp9K6o4HDKQ7O1eoZ9/PbB0bXmE+vtQ8e7WV81fugfFH++X0eEc9RTCEdDyDpfZLuLPV7Invvjz7/vyLiFuBrFGdGf5C0WNKItP6wXsYwpvT8d6XtPJUe7uuNBDYIHABWyzaKV8LHlJaXRsTnS21qXex9iOKA2uOEVFbv+n2SdBjwI4q55+Mi4hjgJorpi1oeoZhqemUvdfWMu8dtwJ8p5u37UmsfDNS4ngfpwvtY4CFJ44F/BeYAx6b9sZG990e/+zsirouI1wIdFNde/pFiX+3qZQw79mMM1mQOAKvlu8DbJJ0rqU3S4ZKmSho7gG0sA66S1C5pNMVc93cb1L9DKebsu4DdkqYDdd3SmF45LwG+JOn4NL7Xp1Cpe9wR8cc0puslXSjpSEnD0pnJF1KzRu+D10qakc46/oEigG4HXkpxgO8CkPQBijOAukh6naQzJA2juHbwDPBcOjv5AbBQ0vAUNJ/YzzFYkzkArF8RsY3iVsZPUxxUtlG8IhzI787ngE5gA8VdJb9MZY3o35+Aj1EcnLqBdwPLB7CJualPd1DcbXMNxdz3gMYdEV+kOCBeVWo/h+J6BDR+H/yU4gJvN/BeYEZE7IqIuynuarqNYgrp1RR3/dRrBMUZRDfFFM+jFHeEQXHh+EmKO63WUVykXrIfY7AmU4S/EMZsKJE0Hzg5Ii5tdl9saPMZgJlZphwAZmaZ8hSQmVmmfAZgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYOaXYHBmL06NFx4oknNrsbZmZDyvr16x+JiPbq8iEVACeeeCKdnZ3N7oaZ2ZAi6cHeyj0FZGaWKQeAmVmmHABmZplyAJiZZcoBYGaWqboCQNISSX+QtLGPekm6TtJWSRsknVaqe7+k/0rL+0vlr5X067TOdZK0/8MxM7N61XsG8G1gWj/104FT0jIb+AaApFHA1cAZwOnA1ZJGpnW+AXyotF5/2zczswarKwAiYg2ws58mFwBLo3A7cIykVwDnAr+IiJ0R0Q38ApiW6kZExO0REcBS4ML9GomZmQ1Io94INgbYVnq+PZX1V769l/IXkTSb4qyCE044oUHd3TeNnqUqss/MrDla/iJwRCyOiEpEVNrbX/RO5sHuS11LvW3NzJqpUQGwAxhXej42lfVXPraXcjMzGySNCoDlwPvS3UBnAn+MiIeBFcBbJY1MF3/fCqxIdY9LOjPd/fM+4KcN6ss+GTVqFJIasgAN29aoUaOauVvM7CBW1zUAScuAqcBoSdsp7uwZBhAR3wRuAs4DtgJPAR9IdTslfRa4I21qQUT0XEz+O4q7i44AfpaWpunu7m7JaRnfHWtmB4pa8aDXl0qlEgfq00AltWwAtGK/zGzokLQ+IirV5S1/EdjMzA4MB4CZWaYcAGZmmXIAmJllakh9JeSBFFePgPlHN7sbLxJXj2h2F8zsIOUASPSZx1vybhtJxPxm98LMDkaeAjIzy5QDwMwsUw4AM7NMOQDMzDLlADAzG6Bly5YxceJE2tramDhxIsuWLWt2l/aJ7wIqacUPXhs5cmTtRmY2aJYtW8a8efP41re+xRvf+EbWrVvHrFmzAJg5c2aTezcw/jC4A8Af4GZ28Jo4cSJf/epXOeuss54vW7VqFZdffjkbN25sYs/61teHwTkADgAHQH38FZs2FLW1tfHMM88wbNiw58t27drF4Ycfzp49e5rYs77500Ct5TTy6zV98LfBMmHCBNatW7dX2bp165gwYUKTerTvHABmZgMwb948Zs2axapVq9i1axerVq1i1qxZzJs3r9ldGzBfBDYzG4CeC72XX345mzdvZsKECSxcuHDIXQAGXwM4IHwNoHG8L832n68BmJnZXhwAZmaZcgCYmWWqrgCQNE3SPZK2Srqil/rxkm6WtEHSakljS3XXSNqYlotL5X8j6ZeS7pS0TtLJjRmSmZnVo2YASGoDrgemAx3ATEkdVc2uBZZGxCRgAbAorXs+cBowGTgDmCup5yuuvgG8JyImA98Hrtr/4RxYkupa6m1rZtZM9ZwBnA5sjYj7IuJZ4Abggqo2HcAt6fGqUn0HsCYidkfEk8AGYFqqC6AnDI4GHtq3IQyeet+Q5DcumdlQUE8AjAG2lZ5vT2VldwEz0uOLgOGSjk3l0yQdKWk0cBYwLrX7IHCTpO3Ae4HP9/bDJc2W1Cmps6urq54xmZlZHRp1EXguMEXSr4ApwA5gT0SsBG4CbgWWAbcBPR+W8XHgvIgYC/wv4Eu9bTgiFkdEJSIq7e3tDequmZnVEwA7eOFVO8DYVPa8iHgoImZExKnAvFT2WPp3YURMjohzAAFbJLUDr4mI/0ybuBF4w/4NxczMBqKeALgDOEXSSZIOBS4BlpcbSBotqWdbVwJLUnlbmgpC0iRgErAS6AaOlvSqtM45wOb9HYyZmdWv5mcBRcRuSXOAFUAbsCQiNklaAHRGxHJgKrBIUgBrgI+m1YcBa9MdL48Dl0bEbgBJHwJ+JOk5ikD47w0dmZmZ9cufBWQtzZ8FZLb//FlAZma2FweAmVmm/H0AZmZVcvm6UgeAmVmVeg/YQ/0alaeAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFN+H4CZZWXUqFF0d3c3bHuNetPYyJEj2blzZ0O2VS8HgJllpbu7uyXfvNWM7wn3FJCZWaYcAHZAjBo1Ckn7vQAN2Y4kRo0a1eS9YtZaPAVkB0QrnmY34xTbrJX5DMDMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFN1BYCkaZLukbRV0hW91I+XdLOkDZJWSxpbqrtG0sa0XFwql6SFkrZI2izpY40ZkpmZ1aPmbaCS2oDrgXOA7cAdkpZHxN2lZtcCSyPiO5LOBhYB75V0PnAaMBk4DFgt6WcR8ThwGTAO+MuIeE7Syxo5MDMz6189ZwCnA1sj4r6IeBa4Abigqk0HcEt6vKpU3wGsiYjdEfEksAGYluo+AiyIiOcAIuIP+z4MMzMbqHoCYAywrfR8eyoruwuYkR5fBAyXdGwqnybpSEmjgbMoXvUDvBK4WFKnpJ9JOqW3Hy5pdmrT2dXVVd+ozMyspka9E3gu8DVJlwFrgB3AnohYKel1wK1AF3AbsCetcxjwTERUJM0AlgBvqt5wRCwGFgNUKpXWemup9SmuHgHzj252N/YSV49odhesBbTi7yY05/dTtd6uL+n1wPyIODc9vxIgIhb10f4o4DcRMbaXuu8D342ImyT9BpgeEfereI/+YxHR7/9KpVKJzs7OesZlTSapJT8KotX6ZIOvVX8PDmS/JK2PiEp1eT1TQHcAp0g6SdKhwCXA8qqNj5bUs60rKV7NI6ktTQUhaRIwCViZ2v2EYkoIYAqwZWBDMjOz/VFzCigidkuaA6wA2oAlEbFJ0gKgMyKWA1OBRZKCYgroo2n1YcDa9CFcjwOXRsTuVPd54HuSPg48AXywccMyM7Naak4BtRJPAQ0drXia3Yp9ssHXqr8HzZgC8sdBm1l2WvGjwUeOHDnoP9MBYGZZaeSr7FY9m6iXPwvIzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTvgvIDphWu9WuGbfZmbUyB4AdEI26NW6o32Zn1so8BWRmlimfAZgdJBo55eazrjw4AMwOEvUctD2lZmWeAjIzy5QDwMwsUw4AM7NMOQDMzDLlADAzy5QDwMwsUw4AM7NMOQDMzDLlADAzy1RdASBpmqR7JG2VdEUv9eMl3Sxpg6TVksaW6q6RtDEtF/ey7nWSnti/YZiZ2UDVDABJbcD1wHSgA5gpqaOq2bXA0oiYBCwAFqV1zwdOAyYDZwBzJY0obbsC+DN6zcyaoJ4zgNOBrRFxX0Q8C9wAXFDVpgO4JT1eVarvANZExO6IeBLYAEyD54PlX4B/2r8hmJnZvqgnAMYA20rPt6eysruAGenxRcBwScem8mmSjpQ0GjgLGJfazQGWR8TD+9p5MzPbd436NNC5wNckXQasAXYAeyJipaTXAbcCXcBtwB5JxwPvAqbW2rCk2cBsgBNOOKFB3TUzs3rOAHbwwqt2gLGp7HkR8VBEzIiIU4F5qeyx9O/CiJgcEecAArYApwInA1slPQAcKWlrbz88IhZHRCUiKu3t7QMbnZmZ9ameM4A7gFMknURx4L8EeHe5QZre2RkRzwFXAktSeRtwTEQ8KmkSMAlYGRG7gZeX1n8iIk5uxIDMzKw+NQMgInZLmgOsANqAJRGxSdICoDMillNM5SySFBRTQB9Nqw8D1qZvKnocuDQd/M3q/garetv5i06sUQby7Wr1tG3V3021asd6U6lUorOzs9ndMBuy/I1geZK0PiIq1eV+J7CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWabqCgBJ0yTdI2mrpCt6qR8v6WZJGyStljS2VHeNpI1pubhU/r20zY2Slkga1pghmZlZPWoGgKQ24HpgOtABzJTUUdXsWmBpREwCFgCL0rrnA6cBk4EzgLmSRqR1vgf8JfBq4Ajgg/s9GjMzq1s9ZwCnA1sj4r6IeBa4Abigqk0HcEt6vKpU3wGsiYjdEfEksAGYBhARN0UC/D9gLGZmNmjqCYAxwLbS8+2prOwuYEZ6fBEwXNKxqXyapCMljQbOAsaVV0xTP+8Ffj7w7puZ2b5q1EXgucAUSb8CpgA7gD0RsRK4CbgVWAbcBuypWvfrFGcJa3vbsKTZkjoldXZ1dTWou2ZmVk8A7GDvV+1jU9nzIuKhiJgREacC81LZY+nfhRExOSLOAQRs6VlP0tVAO/CJvn54RCyOiEpEVNrb2+sclpmZ1VJPANwBnCLpJEmHApcAy8sNJI2W1LOtK4ElqbwtTQUhaRIwCViZnn8QOBeYGRHPNWIwZmZWv5oBEBG7gTnACmAz8IOI2CRpgaS3p2ZTgXskbQGOAxam8mHAWkl3A4uBS9P2AL6Z2t4m6U5J/9yoQZmZWW0qbsIZGiqVSnR2dja7G2ZDliSG0t+8NYak9RFRqS73O4HNzDLlADAzy5QDwMwsUw4AM7NMOQDMzDLlADAzy5QDwMwsUw4AM7NMHdLsDphZ/0aNGkV3d3fDtiepIdsZOXIkO3fubMi2rDkcAGYtrru7uyXfvduoILHm8RSQmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZaquAJA0TdI9krZKuqKX+vGSbpa0QdJqSWNLdddI2piWi0vlJ0n6z7TNGyUd2pghmZlZPWoGgKQ24HpgOtABzJTUUdXsWmBpREwCFgCL0rrnA6cBk4EzgLmSRqR1rgG+HBEnA93ArP0fjpmZ1aueM4DTga0RcV9EPAvcAFxQ1aYDuCU9XlWq7wDWRMTuiHgS2ABMU/ExgmcDP0ztvgNcuO/DMDOzgaonAMYA20rPt6eysruAGenxRcBwScem8mmSjpQ0GjgLGAccCzwWEbv72aaZmR1AjboIPBeYIulXwBRgB7AnIlYCNwG3AsuA24A9A9mwpNmSOiV1dnV1Nai7ZmZWTwDsoHjV3mNsKnteRDwUETMi4lRgXip7LP27MCImR8Q5gIAtwKPAMZIO6WubpW0vjohKRFTa29sHMDQzM+tPPQFwB3BKumvnUOASYHm5gaTRknq2dSWwJJW3pakgJE0CJgEro/h6o1XAO9M67wd+ur+DMTOz+tUMgDRPPwdYAWwGfhARmyQtkPT21GwqcI+kLcBxwMJUPgxYK+luYDFwaWne/1PAJyRtpbgm8K0GjcnMzOqgVvyu0b5UKpXo7OxsdjfMBpWklv1O4Fbsl72YpPURUaku9zuBzcwy5QAwM8uUA8DMLFMOADOzTB1Su4mZNVNcPQLmH93sbrxIXD2idiNraQ4AsxanzzzeknfbSCLmN7sXtj88BWRmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWWqrgCQNE3SPZK2Srqil/rxkm6WtEHSakljS3VfkLRJ0mZJ10lSKp8p6ddpnZ9LGt24YZmZWS01A0BSG3A9MB3oAGZK6qhqdi2wNCImAQuARWndNwB/DUwCJgKvA6ZIOgT4n8BZaZ0NwJyGjMjMzOpSzxnA6cDWiLgvIp4FbgAuqGrTAdySHq8q1QdwOHAocBgwDPg9oLS8NJ0RjAAe2o9xmJnZANUTAGOAbaXn21NZ2V3AjPT4ImC4pGMj4jaKQHg4LSsiYnNE7AI+Avya4sDfAXyrtx8uabakTkmdXV1ddQ7LzMxqadRF4LkUUzu/AqYAO4A9kk4GJgBjKULjbElvkjSMIgBOBY6nmAK6srcNR8TiiKhERKW9vb1B3TUzs0PqaLMDGFd6PjaVPS8iHiKdAUg6CnhHRDwm6UPA7RHxRKr7GfB64Jm03r2p/AfAiy4um5nZgVPPGcAdwCmSTpJ0KHAJsLzcQNJoST3buhJYkh7/lnTRN73qnwJspgiQDkk9L+nPSeVmZjZIap4BRMRuSXOAFUAbsCQiNklaAHRGxHJgKrBIUgBrgI+m1X8InE0x1x/AzyPiPwAkfQZYI2kX8CBwWSMHZmZm/VNENLsPdatUKtHZ2dnsbpgNKkm04t9pq/bLXkzS+oioVJf7ncBmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZpmq58PgzKzJ0hfptZSRI0c2uwu2nxwAZi2ukR+34I9vsDIHgNlBot6zhHraOSTy4AAwO0j4oG0D5YvAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZpjSU3jwiqQt4sNn9qMNo4JFmd+Ig4X3ZWN6fjTVU9uf4iGivLhxSATBUSOqMiEqz+3Ew8L5sLO/Pxhrq+9NTQGZmmXIAmJllygFwYCxudgcOIt6XjeX92VhDen/6GoCZWaZ8BmBmlikHQB0kvVzSDZLulbRe0k2SXpXq/kHSM5KOLrWfKumPku6U9BtJ10p6dXp+p6Sdku5Pj/9P80bWXJLmSdokaUPaF1dLWlTVZrKkzenxA5LWVtXfKWnjYPZ7KJAUkr5Yej5X0vz0eL6kHaXfz29I8rGgRNITpcfnSdoiaXzad09Jelkfbfvc763I/+k1qPj6pB8DqyPilRHxWuBK4LjUZCZwBzCjatW1ETEZOBX4W2BERExOZcuBf0zP3zIoA2kxkl5PsV9Oi4hJwFuAVcDFVU0vAZaVng+XNC5tY8Jg9HWI+jMwQ9LoPuq/nH4XO4BXA1MGrWdDiKS/Aa4DpkdEz3uQHgE+2ccqtfZ7S3EA1HYWsCsivtlTEBF3RcRaSa8EjgKuogiCF4mIp4E7gTGD0dkh5BXAIxHxZ4CIeCQi1gDdks4otftv7B0AP+CFkJhZVWcv2E1xgfLjNdodChwOdB/wHg0xkt4M/CvwtxFxb6lqCXCxpFG9rFbvfm8JDoDaJgLr+6i7BLgBWAv8haTjqhtIGgmcAqw5YD0cmlYC49Kp9dcl9bwCXUaxX5F0JrAzIv6rtN6PeOFs623AfwxWh4eg64H3lKcnSz4u6U7gYWBLRNw5uF1reYcBPwEujIjfVNU9QRECf9/Huv3t95biANg/M4EbIuI5igPTu0p1b5J0F7ADWBERv2tGB1tVRDwBvBaYDXQBN0q6DLgReGeak66e/gF4lOIs4RJgM/DUoHV6iImIx4GlwMd6qe6ZAnoZ8NK0P+0Fu4BbgVl91F8HvF/S8OqKGvu9pTgAattEcaDai6RXU7yy/4WkBygOVuVpoLUR8Rrgr4BZkiYPQl+HlIjYExGrI+JqYA7wjojYBtxPMSf9DopAqHYjxassT//U9hWKg9hLe6uMiF3Az4E3D2anhoDnKKYfT5f06erKiHgM+D7w0T7W73e/twoHQG23AIdJmt1TIGkSxSuA+RFxYlqOB46XNL68ckTcD3we+NRgdrrVSfoLSaeUiibzwgf9LQO+DNwXEdt7Wf3HwBeAFQe2l0NfROykuG7S6yvZdJPDXwP39lafs4h4CjifYjqnt/33JeDDwCG9rNvvfm8VDoAaonin3EXAW9JtoJuARcBUigNR2Y9J89dVvgm8WdKJB66nQ85RwHck3S1pA8XdKPNT3b9TnDn1+go/Iv4UEddExLOD0tOh74sUn1pZ1nMNYCPQBnx90Hs1BKQD+TTgKklvr6p7hOJv/rA+Vu9tv7cUvxPYzCxTPgMwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy9f8BdtUDniyqXD8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZF_bu1byp_7"
      },
      "source": [
        "#PIPELINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUhaIHb2xTth",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "571408a3-46c7-4317-a190-55040563c3e1"
      },
      "source": [
        "import warnings\n",
        "\n",
        "# Standardize the dataset\n",
        "pipelines = []\n",
        "\n",
        "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART',\n",
        "                                                                        DecisionTreeClassifier())])))\n",
        "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC( ))])))\n",
        "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB',\n",
        "                                                                      GaussianNB())])))\n",
        "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',\n",
        "                                                                       KNeighborsClassifier())])))\n",
        "results = []\n",
        "names = []\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    kfold = KFold(n_splits=num_folds, random_state=123)\n",
        "    for name, model in pipelines:\n",
        "        start = time.time()\n",
        "        cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
        "        end = time.time()\n",
        "        results.append(cv_results)\n",
        "        names.append(name)\n",
        "        print( \"%s: %f (%f) (run time: %f)\" % (name, cv_results.mean(), cv_results.std(), end-start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ScaledCART: 0.999062 (0.000753) (run time: 3.129308)\n",
            "ScaledSVM: 0.998687 (0.000946) (run time: 6.099161)\n",
            "ScaledNB: 0.984500 (0.003281) (run time: 0.208195)\n",
            "ScaledKNN: 0.999375 (0.000625) (run time: 14.916771)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzzZxMIOyHAZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "f3c0266a-d833-4d2a-9887-b28b1ac91a3d"
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.suptitle('Performance Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhNKDyAO1MiO"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nctkC0t6yHHP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "6dee7106-0bd9-443e-9d3e-b9a04011f0ab"
      },
      "source": [
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
        "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "param_grid = dict(C=c_values, kernel=kernel_values)\n",
        "model = SVC()\n",
        "kfold = KFold(n_splits=num_folds)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=kfold)\n",
        "grid_result = grid.fit(rescaledX, Y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.999625 using {'C': 0.1, 'kernel': 'linear'}\n",
            "0.999625 (0.000415) with: {'C': 0.1, 'kernel': 'linear'}\n",
            "0.999563 (0.000628) with: {'C': 0.1, 'kernel': 'poly'}\n",
            "0.996063 (0.001342) with: {'C': 0.1, 'kernel': 'rbf'}\n",
            "0.998375 (0.000848) with: {'C': 0.1, 'kernel': 'sigmoid'}\n",
            "0.999563 (0.000488) with: {'C': 0.3, 'kernel': 'linear'}\n",
            "0.999500 (0.000468) with: {'C': 0.3, 'kernel': 'poly'}\n",
            "0.996625 (0.001256) with: {'C': 0.3, 'kernel': 'rbf'}\n",
            "0.997687 (0.001342) with: {'C': 0.3, 'kernel': 'sigmoid'}\n",
            "0.999500 (0.000468) with: {'C': 0.5, 'kernel': 'linear'}\n",
            "0.999438 (0.000519) with: {'C': 0.5, 'kernel': 'poly'}\n",
            "0.998000 (0.001146) with: {'C': 0.5, 'kernel': 'rbf'}\n",
            "0.997375 (0.001335) with: {'C': 0.5, 'kernel': 'sigmoid'}\n",
            "0.999500 (0.000468) with: {'C': 0.7, 'kernel': 'linear'}\n",
            "0.999438 (0.000519) with: {'C': 0.7, 'kernel': 'poly'}\n",
            "0.998500 (0.000848) with: {'C': 0.7, 'kernel': 'rbf'}\n",
            "0.997125 (0.001317) with: {'C': 0.7, 'kernel': 'sigmoid'}\n",
            "0.999375 (0.000625) with: {'C': 0.9, 'kernel': 'linear'}\n",
            "0.999438 (0.000519) with: {'C': 0.9, 'kernel': 'poly'}\n",
            "0.998687 (0.000904) with: {'C': 0.9, 'kernel': 'rbf'}\n",
            "0.997062 (0.001557) with: {'C': 0.9, 'kernel': 'sigmoid'}\n",
            "0.999375 (0.000625) with: {'C': 1.0, 'kernel': 'linear'}\n",
            "0.999438 (0.000519) with: {'C': 1.0, 'kernel': 'poly'}\n",
            "0.998687 (0.000946) with: {'C': 1.0, 'kernel': 'rbf'}\n",
            "0.997125 (0.001561) with: {'C': 1.0, 'kernel': 'sigmoid'}\n",
            "0.999375 (0.000625) with: {'C': 1.3, 'kernel': 'linear'}\n",
            "0.999438 (0.000519) with: {'C': 1.3, 'kernel': 'poly'}\n",
            "0.998812 (0.000904) with: {'C': 1.3, 'kernel': 'rbf'}\n",
            "0.996937 (0.001354) with: {'C': 1.3, 'kernel': 'sigmoid'}\n",
            "0.999313 (0.000590) with: {'C': 1.5, 'kernel': 'linear'}\n",
            "0.999438 (0.000519) with: {'C': 1.5, 'kernel': 'poly'}\n",
            "0.998812 (0.000904) with: {'C': 1.5, 'kernel': 'rbf'}\n",
            "0.996937 (0.001354) with: {'C': 1.5, 'kernel': 'sigmoid'}\n",
            "0.999250 (0.000545) with: {'C': 1.7, 'kernel': 'linear'}\n",
            "0.999438 (0.000519) with: {'C': 1.7, 'kernel': 'poly'}\n",
            "0.998875 (0.000875) with: {'C': 1.7, 'kernel': 'rbf'}\n",
            "0.996937 (0.001354) with: {'C': 1.7, 'kernel': 'sigmoid'}\n",
            "0.999250 (0.000545) with: {'C': 2.0, 'kernel': 'linear'}\n",
            "0.999375 (0.000625) with: {'C': 2.0, 'kernel': 'poly'}\n",
            "0.998875 (0.000875) with: {'C': 2.0, 'kernel': 'rbf'}\n",
            "0.997125 (0.001375) with: {'C': 2.0, 'kernel': 'sigmoid'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebA8q_w4yHM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e50a745-fc46-4c4e-f008-0f2669055a3e"
      },
      "source": [
        "# prepare the model\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "SVM = SVC(C=0.1, kernel='linear')\n",
        "start = time.time()\n",
        "SVM.fit(X_train_scaled, Y_train)\n",
        "end = time.time()\n",
        "print( \"Run Time: %f\" % (end-start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run Time: 0.091443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijCBx7I_yHFz"
      },
      "source": [
        "# estimate accuracy on test dataset\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "SVM_pred = SVM.predict(X_test_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi7-k4ARyd1N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "39f1cf5f-48d1-4f37-d264-df8120fa6ef9"
      },
      "source": [
        "print(confusion_matrix(Y_test, SVM_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3980    1]\n",
            " [   1   18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5_824s9QyCO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ec8e26f-3a76-4f96-f9b4-4e34935578d8"
      },
      "source": [
        "accuracy = accuracy_score(Y_test, SVM_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5tQavw-yZqZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "896c08c0-0401-4ed9-cd12-b7e9aeece3d3"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, SVM_pred))\n",
        "print(classification_report(Y_test, SVM_pred))\n",
        "\n",
        "\"\"\"\n",
        "Accuracy score 0.999500\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00      3982\n",
        "           1       1.00      0.89      0.94        18\n",
        "\n",
        "    accuracy                           1.00      4000\n",
        "   macro avg       1.00      0.94      0.97      4000\n",
        "weighted avg       1.00      1.00      1.00      4000\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.999500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3981\n",
            "           1       0.95      0.95      0.95        19\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       0.97      0.97      0.97      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAccuracy score 0.999500\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00      3982\\n           1       1.00      0.89      0.94        18\\n\\n    accuracy                           1.00      4000\\n   macro avg       1.00      0.94      0.97      4000\\nweighted avg       1.00      1.00      1.00      4000\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni0WiBNW1VdB"
      },
      "source": [
        "#NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7kMtx5-1ZMW"
      },
      "source": [
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "X = X.reshape(-1,1)\n",
        "Y = Y.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_DOUaaZ1ZJ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e63c6d0f-b2d1-432a-bf25-57f9fe48e9a7"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "NB = GaussianNB()\n",
        "NB.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa14iXmd1ZIp"
      },
      "source": [
        "NB_pred = NB.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDwM-jHX1ZCD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62cbe027-b9dc-4db1-d40a-d22f772ed910"
      },
      "source": [
        "NB.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecNO56LS1Y93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f007b073-4a29-4b7b-db27-fe73f2f6cd69"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, NB_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3908   73]\n",
            " [   0   19]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1PpE1bYQtLC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b6871b9-e1cc-4dea-e200-695463e8f65b"
      },
      "source": [
        "accuracy = accuracy_score(Y_test, NB_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 98.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMDRqfvbE3jC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c27913f8-d409-4dfc-ff8f-628203f7bcbc"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, NB_pred))\n",
        "print(classification_report(Y_test, NB_pred))\n",
        "\n",
        "\"\"\"\n",
        "Accuracy score 0.980750\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      0.98      0.99      3977\n",
        "           1       0.23      1.00      0.37        23\n",
        "\n",
        "    accuracy                           0.98      4000\n",
        "   macro avg       0.61      0.99      0.68      4000\n",
        "weighted avg       1.00      0.98      0.99      4000\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.981750\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      3981\n",
            "           1       0.21      1.00      0.34        19\n",
            "\n",
            "    accuracy                           0.98      4000\n",
            "   macro avg       0.60      0.99      0.67      4000\n",
            "weighted avg       1.00      0.98      0.99      4000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAccuracy score 0.980750\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.98      0.99      3977\\n           1       0.23      1.00      0.37        23\\n\\n    accuracy                           0.98      4000\\n   macro avg       0.61      0.99      0.68      4000\\nweighted avg       1.00      0.98      0.99      4000\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7qiblRq15S8"
      },
      "source": [
        "#DT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vYHINgh1t6R"
      },
      "source": [
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnHsoAhY16e8"
      },
      "source": [
        "X = X.reshape(-1,1)\n",
        "Y = Y.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j_fA2NM2Ci2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ea664768-0baa-47bb-8595-3cbaba988495"
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(600000, 1)\n",
            "(20000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_9z888W2DQh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "94656918-71e4-4a9c-fcb8-32d597f1a8c0"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DT = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "DT.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "778-DyWy2F_L"
      },
      "source": [
        "DT_pred = DT.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaw2K3FF2JO2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "57ccb587-1cf3-4a47-a929-559834ca63ac"
      },
      "source": [
        "DT.score(X_test, Y_test)\n",
        "DT.fit(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F96rdu8v2LNT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31f9dcbc-b4f6-477b-d03b-268c3459a0ea"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, DT_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3981    0]\n",
            " [   1   18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjgcubEkQqoM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "623105be-e099-4a46-d5db-9cc457eac403"
      },
      "source": [
        "accuracy = accuracy_score(Y_test, DT_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5qb72N1FCku",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "1cc65993-d15d-419a-da77-f35c321b45a8"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, DT_pred))\n",
        "print(classification_report(Y_test, DT_pred))\n",
        "\n",
        "\"\"\"\n",
        "Accuracy score 1.000000\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00      3977\n",
        "           1       1.00      1.00      1.00        23\n",
        "\n",
        "    accuracy                           1.00      4000\n",
        "   macro avg       1.00      1.00      1.00      4000\n",
        "weighted avg       1.00      1.00      1.00      4000\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.999750\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3981\n",
            "           1       1.00      0.95      0.97        19\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       1.00      0.97      0.99      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAccuracy score 1.000000\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00      3977\\n           1       1.00      1.00      1.00        23\\n\\n    accuracy                           1.00      4000\\n   macro avg       1.00      1.00      1.00      4000\\nweighted avg       1.00      1.00      1.00      4000\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veF8CoaY_Jdm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0842c47d-f271-4c5f-b3d9-de4afd12c204"
      },
      "source": [
        "!pip install pydotplus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from pydotplus) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oGSeOf2_Jtk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ed07542d-8b4b-488b-feb0-06297c5d99d5"
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.externals.six import StringIO\n",
        "import pydotplus\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn import tree\n",
        "%matplotlib inline \n",
        "\n",
        "dot_data = StringIO()\n",
        "filename = \"creditcardfraudtree.png\"\n",
        "featureNames = data.columns[:-1]\n",
        "targetNames = data[\"Class\"].unique().tolist()\n",
        "out=tree.export_graphviz(DT,feature_names=featureNames, out_file=dot_data, class_names= np.unique(Y_train), filled=True,  special_characters=True,rotate=False)  \n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png(filename)\n",
        "img = mpimg.imread(filename)\n",
        "plt.figure(figsize=(100, 200))\n",
        "plt.imshow(img,interpolation='nearest')\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.externals.six import StringIO\\nimport pydotplus\\nimport matplotlib.image as mpimg\\nfrom sklearn import tree\\n%matplotlib inline \\n\\ndot_data = StringIO()\\nfilename = \"creditcardfraudtree.png\"\\nfeatureNames = data.columns[:-1]\\ntargetNames = data[\"Class\"].unique().tolist()\\nout=tree.export_graphviz(DT,feature_names=featureNames, out_file=dot_data, class_names= np.unique(Y_train), filled=True,  special_characters=True,rotate=False)  \\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \\ngraph.write_png(filename)\\nimg = mpimg.imread(filename)\\nplt.figure(figsize=(100, 200))\\nplt.imshow(img,interpolation=\\'nearest\\')'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFcVKYY7V715"
      },
      "source": [
        "#DECISON TREE BAGGING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvTIZqkeV6SU"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "Bagging = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H_XDDubV7D3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2821f0d-1884-4e1b-fced-474fd5498d8a"
      },
      "source": [
        "Bagging.fit(X_train, Y_train)\n",
        "B_pred = Bagging.predict(X_test)\n",
        "print(Y_test, B_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0] [0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp_fEWcTV7Ax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6ddc869-715f-4f9e-e4ce-e042a4fad6f9"
      },
      "source": [
        "Bagging.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHA989gFc0cY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e2fe535d-e826-4b7b-c2ee-0b51d4e28a13"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, B_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3981    0]\n",
            " [   1   18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bJoehLjQmXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "736d30f7-c008-4078-8940-0b4724e6a519"
      },
      "source": [
        "accuracy = accuracy_score(Y_test, B_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TDyX9JPc0W4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "e7d8f32c-98bc-4eee-ec89-a9fd239b5ed8"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, B_pred))\n",
        "print(classification_report(Y_test, B_pred))\n",
        "\n",
        "\"\"\"\n",
        "Accuracy score 0.999500\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00      3977\n",
        "           1       1.00      0.91      0.95        23\n",
        "\n",
        "    accuracy                           1.00      4000\n",
        "   macro avg       1.00      0.96      0.98      4000\n",
        "weighted avg       1.00      1.00      1.00      4000\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.999750\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3981\n",
            "           1       1.00      0.95      0.97        19\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       1.00      0.97      0.99      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAccuracy score 0.999500\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00      3977\\n           1       1.00      0.91      0.95        23\\n\\n    accuracy                           1.00      4000\\n   macro avg       1.00      0.96      0.98      4000\\nweighted avg       1.00      1.00      1.00      4000\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltwo4bpdfUJB"
      },
      "source": [
        "#EXTRA TREE CLASSFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVOxJXgyfYKV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02c76108-2865-4d80-b6d2-a2aac3fafe9c"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "ET = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
        "\n",
        "ET.fit(X_train, Y_train)\n",
        "ET.score(X_train, Y_train)\n",
        "\n",
        "ET_pred = ET.predict(X_test)\n",
        "ET.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65zKOlAHfX-y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fb4775d9-6665-42d7-a2e5-df8514e7b193"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, ET_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3981    0]\n",
            " [   1   18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFlomRnPQiGT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a19a2e0-05ef-494e-cb30-009a0871c9fb"
      },
      "source": [
        "accuracy = accuracy_score(Y_test, ET_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in2vcWAJgUwx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "82fb3bd2-e1a7-4e2a-a381-d19861ae03f2"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, ET_pred))\n",
        "print(classification_report(Y_test, ET_pred))\n",
        "\n",
        "\"\"\"\n",
        "Accuracy score 0.999250\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00      3977\n",
        "           1       1.00      0.87      0.93        23\n",
        "\n",
        "    accuracy                           1.00      4000\n",
        "   macro avg       1.00      0.93      0.96      4000\n",
        "weighted avg       1.00      1.00      1.00      4000\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.999750\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3981\n",
            "           1       1.00      0.95      0.97        19\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       1.00      0.97      0.99      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAccuracy score 0.999250\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00      3977\\n           1       1.00      0.87      0.93        23\\n\\n    accuracy                           1.00      4000\\n   macro avg       1.00      0.93      0.96      4000\\nweighted avg       1.00      1.00      1.00      4000\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZyd_Hfz2oLo"
      },
      "source": [
        "#RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiR0t-PM2NMZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55611f61-5675-40d0-f3f6-269013998502"
      },
      "source": [
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "X = X.reshape(-1,1)\n",
        "Y = Y.reshape(-1,1)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF = RandomForestClassifier(criterion='entropy', random_state=0)\n",
        "RF.fit(X_train,Y_train)\n",
        "RF_pred = RF.predict(X_test)\n",
        "RF.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfNHsez_2THS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a20d0891-3b58-45df-f1ca-6454889c295b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, RF_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3980    1]\n",
            " [   1   18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fn_dacEQTpE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "424a98f3-ecc0-4446-9261-4a8cdfb45e72"
      },
      "source": [
        "accuracy = accuracy_score(Y_test, RF_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZpLlxwEFNll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9fc2d586-a906-4db5-b212-3959f87a5fe6"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, RF_pred))\n",
        "print(classification_report(Y_test, RF_pred))\n",
        "\n",
        "\"\"\"\n",
        "Accuracy score 0.999500\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00      3977\n",
        "           1       1.00      0.91      0.95        23\n",
        "\n",
        "    accuracy                           1.00      4000\n",
        "   macro avg       1.00      0.96      0.98      4000\n",
        "weighted avg       1.00      1.00      1.00      4000\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.999500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3981\n",
            "           1       0.95      0.95      0.95        19\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       0.97      0.97      0.97      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAccuracy score 0.999500\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00      3977\\n           1       1.00      0.91      0.95        23\\n\\n    accuracy                           1.00      4000\\n   macro avg       1.00      0.96      0.98      4000\\nweighted avg       1.00      1.00      1.00      4000\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzr01v1ThHp3"
      },
      "source": [
        "#GRADIANT DESCENT CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBjwDnwdhZFW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "027884ba-e258-4544-feab-893395eb0000"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GB = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "GB.fit(X_train, Y_train)\n",
        "\n",
        "GB_pred = GB.predict(X_test)\n",
        "GB.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7X4yjnWhY_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f551459f-a032-46a2-ab5e-85e54243a2fc"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, GB_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3977    4]\n",
            " [   0   19]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97yLVNwHQLMN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a575307a-ef61-4574-f52f-4ce588b2ab54"
      },
      "source": [
        "accuracy = accuracy_score(Y_test, GB_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZaponhRhY9E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "fdf646a8-7c02-4325-aef4-edae14185e87"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, GB_pred))\n",
        "print(classification_report(Y_test, GB_pred))\n",
        "\n",
        "\"\"\"\n",
        "Accuracy score 0.998250\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00      3977\n",
        "           1       0.81      0.91      0.86        23\n",
        "\n",
        "    accuracy                           1.00      4000\n",
        "   macro avg       0.90      0.96      0.93      4000\n",
        "weighted avg       1.00      1.00      1.00      4000\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.999000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3981\n",
            "           1       0.83      1.00      0.90        19\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       0.91      1.00      0.95      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAccuracy score 0.998250\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00      3977\\n           1       0.81      0.91      0.86        23\\n\\n    accuracy                           1.00      4000\\n   macro avg       0.90      0.96      0.93      4000\\nweighted avg       1.00      1.00      1.00      4000\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNRXrNXEH6wv"
      },
      "source": [
        "#XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4V9tFc9H5fv"
      },
      "source": [
        "import xgboost\n",
        "\n",
        "XGB = xgboost.XGBClassifier(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75)\n",
        "XGB.fit(X_train, Y_train , verbose=False)\n",
        "\n",
        "XGB_pred = XGB.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOdxtHHyO44m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c987b94a-948b-42da-d661-a73810522e1f"
      },
      "source": [
        "\"\"\"XGBPred = []\n",
        "for i in XGB_pred:\n",
        "  for k in i:\n",
        "    XGBPred.append(str(int(k)))\n",
        "\n",
        "XGBPred = np.array(XGBPred)\n",
        "XGBPred\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'XGBPred = []\\nfor i in XGB_pred:\\n  for k in i:\\n    XGBPred.append(str(int(k)))\\n\\nXGBPred = np.array(XGBPred)\\nXGBPred'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsnTJsQ5O5js",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4e909ec-15c9-4e23-9189-4c2d81adcfbf"
      },
      "source": [
        "accuracy = accuracy_score(Y_test, XGB_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWSO9s4Phs5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d60dbabb-f955-41c9-ccd5-ab95daa8bc9d"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, XGB_pred))\n",
        "print(classification_report(Y_test, XGB_pred))\n",
        "\n",
        "\"\"\"\n",
        "Accuracy score 0.999750\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00      3981\n",
        "           1       0.95      1.00      0.97        19\n",
        "\n",
        "    accuracy                           1.00      4000\n",
        "   macro avg       0.97      1.00      0.99      4000\n",
        "weighted avg       1.00      1.00      1.00      4000\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.999500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3981\n",
            "           1       0.95      0.95      0.95        19\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       0.97      0.97      0.97      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAccuracy score 0.999750\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00      3981\\n           1       0.95      1.00      0.97        19\\n\\n    accuracy                           1.00      4000\\n   macro avg       0.97      1.00      0.99      4000\\nweighted avg       1.00      1.00      1.00      4000\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2NV_zuNP3vE"
      },
      "source": [
        "#ADABOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awv3ur1UP6kr"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ADABoost = AdaBoostClassifier()\n",
        "ADABoost.fit(X_train, Y_train)\n",
        "\n",
        "ADAB_pred = ADABoost.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF9stKJ-P6iS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68ae4f54-53d5-427c-f536-f25f04de3897"
      },
      "source": [
        "\"\"\"ADABPred = []\n",
        "for i in ADAB_pred:\n",
        "  for k in i:\n",
        "    ADABPred.append(str(int(k)))\n",
        "\n",
        "ADABPred = np.array(ADABPred)\n",
        "ADABPred\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ADABPred = []\\nfor i in ADAB_pred:\\n  for k in i:\\n    ADABPred.append(str(int(k)))\\n\\nADABPred = np.array(ADABPred)\\nADABPred'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-FsxAUWP6gK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ae10b2a-80bf-44a5-9554-0ad55935f081"
      },
      "source": [
        "accuracy = accuracy_score(Y_test, ADAB_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFmzqheIPzkm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "f80f576a-1d51-4694-e23f-cf996e328af7"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, ADAB_pred))\n",
        "print(classification_report(Y_test, ADAB_pred))\n",
        "\n",
        "\"\"\"\n",
        "Accuracy score 0.999000\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00      3989\n",
        "           1       1.00      0.64      0.78        11\n",
        "\n",
        "    accuracy                           1.00      4000\n",
        "   macro avg       1.00      0.82      0.89      4000\n",
        "weighted avg       1.00      1.00      1.00      4000\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.999250\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3981\n",
            "           1       0.90      0.95      0.92        19\n",
            "\n",
            "    accuracy                           1.00      4000\n",
            "   macro avg       0.95      0.97      0.96      4000\n",
            "weighted avg       1.00      1.00      1.00      4000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAccuracy score 0.999000\\n              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00      3989\\n           1       1.00      0.64      0.78        11\\n\\n    accuracy                           1.00      4000\\n   macro avg       1.00      0.82      0.89      4000\\nweighted avg       1.00      1.00      1.00      4000\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWm6WYhm4Fgj"
      },
      "source": [
        "#ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMxQuu8W4NZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "6fe69ea6-6d0c-486f-a3d2-e45d0e312a5e"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnOZLU9mNdNL"
      },
      "source": [
        "Y = df['Class'].values\n",
        "X = df.drop('Class', axis=1).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLxVmwKG7fVi"
      },
      "source": [
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test =sc_X.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoYzMitY7kdw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "56e68416-d7e0-4ad4-8f96-aba956096d56"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units = 100, activation = 'relu', input_shape=(30,)))\n",
        "\n",
        "model.add(Dense(units = 50, activation = 'relu'))\n",
        "\n",
        "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 100)               3100      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,201\n",
            "Trainable params: 8,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygsKy91V7wKC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8663c56-af33-455d-b4b5-caae68bb6a2e"
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size = 50, nb_epoch = 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 0.0063 - accuracy: 0.9991\n",
            "Epoch 2/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Epoch 3/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Epoch 4/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0024 - accuracy: 0.9995\n",
            "Epoch 5/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 0.0023 - accuracy: 0.9995\n",
            "Epoch 6/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 7/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0019 - accuracy: 0.9996\n",
            "Epoch 8/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 9/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0016 - accuracy: 0.9996\n",
            "Epoch 10/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 11/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 12/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 13/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0013 - accuracy: 0.9996\n",
            "Epoch 14/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0015 - accuracy: 0.9997\n",
            "Epoch 15/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 16/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 17/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 18/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 19/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 20/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 8.9692e-04 - accuracy: 0.9997\n",
            "Epoch 21/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 8.9367e-04 - accuracy: 0.9997\n",
            "Epoch 22/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 8.3463e-04 - accuracy: 0.9998\n",
            "Epoch 23/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 8.5328e-04 - accuracy: 0.9998\n",
            "Epoch 24/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 7.9720e-04 - accuracy: 0.9997\n",
            "Epoch 25/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 8.5995e-04 - accuracy: 0.9997\n",
            "Epoch 26/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 7.1956e-04 - accuracy: 0.9998\n",
            "Epoch 27/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 7.9557e-04 - accuracy: 0.9998\n",
            "Epoch 28/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 6.1946e-04 - accuracy: 0.9998\n",
            "Epoch 29/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 6.5365e-04 - accuracy: 0.9998\n",
            "Epoch 30/500\n",
            "227845/227845 [==============================] - 7s 30us/step - loss: 7.2125e-04 - accuracy: 0.9998\n",
            "Epoch 31/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 5.7845e-04 - accuracy: 0.9998\n",
            "Epoch 32/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 5.1822e-04 - accuracy: 0.9998\n",
            "Epoch 33/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 6.3177e-04 - accuracy: 0.9998\n",
            "Epoch 34/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 6.3415e-04 - accuracy: 0.9998\n",
            "Epoch 35/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 8.3755e-04 - accuracy: 0.9998\n",
            "Epoch 36/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 6.1220e-04 - accuracy: 0.9998\n",
            "Epoch 37/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 6.7466e-04 - accuracy: 0.9998\n",
            "Epoch 38/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 6.4958e-04 - accuracy: 0.9998\n",
            "Epoch 39/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.1637e-04 - accuracy: 0.9999\n",
            "Epoch 40/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.9149e-04 - accuracy: 0.9998\n",
            "Epoch 41/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 6.5492e-04 - accuracy: 0.9998\n",
            "Epoch 42/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.0611e-04 - accuracy: 0.9998\n",
            "Epoch 43/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 6.4743e-04 - accuracy: 0.9998\n",
            "Epoch 44/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.1348e-04 - accuracy: 0.9999\n",
            "Epoch 45/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.8710e-04 - accuracy: 0.9998\n",
            "Epoch 46/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.3501e-04 - accuracy: 0.9998\n",
            "Epoch 47/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.1121e-04 - accuracy: 0.9999\n",
            "Epoch 48/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.8146e-04 - accuracy: 0.9998\n",
            "Epoch 49/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.8001e-04 - accuracy: 0.9998\n",
            "Epoch 50/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.8555e-04 - accuracy: 0.9999\n",
            "Epoch 51/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 5.3295e-04 - accuracy: 0.9999\n",
            "Epoch 52/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.4058e-04 - accuracy: 0.9999\n",
            "Epoch 53/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.5479e-04 - accuracy: 0.9999\n",
            "Epoch 54/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5669e-04 - accuracy: 0.9999\n",
            "Epoch 55/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.0467e-04 - accuracy: 0.9999\n",
            "Epoch 56/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.4545e-04 - accuracy: 0.9999\n",
            "Epoch 57/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.7747e-04 - accuracy: 0.9999\n",
            "Epoch 58/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 7.6826e-04 - accuracy: 0.9999\n",
            "Epoch 59/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 2.8508e-04 - accuracy: 0.9999\n",
            "Epoch 60/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6234e-04 - accuracy: 0.9999\n",
            "Epoch 61/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.0981e-04 - accuracy: 0.9999\n",
            "Epoch 62/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.7792e-04 - accuracy: 0.9999\n",
            "Epoch 63/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.2056e-04 - accuracy: 0.9999\n",
            "Epoch 64/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.0069e-04 - accuracy: 0.9999\n",
            "Epoch 65/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.0314e-04 - accuracy: 0.9999\n",
            "Epoch 66/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.8599e-04 - accuracy: 0.9999\n",
            "Epoch 67/500\n",
            "227845/227845 [==============================] - 8s 34us/step - loss: 3.2927e-04 - accuracy: 0.9999\n",
            "Epoch 68/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.1599e-04 - accuracy: 0.9999\n",
            "Epoch 69/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.5609e-04 - accuracy: 0.9999\n",
            "Epoch 70/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.4222e-04 - accuracy: 0.9999\n",
            "Epoch 71/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.1612e-04 - accuracy: 0.9999\n",
            "Epoch 72/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.5229e-04 - accuracy: 0.9999\n",
            "Epoch 73/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5609e-04 - accuracy: 0.9999\n",
            "Epoch 74/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 4.1065e-04 - accuracy: 0.9999\n",
            "Epoch 75/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3462e-04 - accuracy: 0.9999\n",
            "Epoch 76/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.7628e-04 - accuracy: 0.9999\n",
            "Epoch 77/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4232e-04 - accuracy: 0.9999\n",
            "Epoch 78/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.2372e-04 - accuracy: 0.9999\n",
            "Epoch 79/500\n",
            "227845/227845 [==============================] - 7s 30us/step - loss: 3.1166e-04 - accuracy: 0.9999\n",
            "Epoch 80/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 3.7968e-04 - accuracy: 0.9999\n",
            "Epoch 81/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 4.1482e-04 - accuracy: 0.9999\n",
            "Epoch 82/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.7326e-04 - accuracy: 0.9999\n",
            "Epoch 83/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.3949e-04 - accuracy: 0.9999\n",
            "Epoch 84/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.9382e-04 - accuracy: 0.9999\n",
            "Epoch 85/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4002e-04 - accuracy: 0.9999\n",
            "Epoch 86/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.2767e-04 - accuracy: 0.9999\n",
            "Epoch 87/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.7796e-04 - accuracy: 0.9999\n",
            "Epoch 88/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.2863e-04 - accuracy: 0.9999\n",
            "Epoch 89/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.0393e-04 - accuracy: 0.9999\n",
            "Epoch 90/500\n",
            "227845/227845 [==============================] - 7s 30us/step - loss: 3.6159e-04 - accuracy: 0.9999\n",
            "Epoch 91/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3849e-04 - accuracy: 0.9999\n",
            "Epoch 92/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 3.2946e-04 - accuracy: 0.9999\n",
            "Epoch 93/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2293e-04 - accuracy: 0.9999\n",
            "Epoch 94/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.4333e-04 - accuracy: 0.9998\n",
            "Epoch 95/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.2151e-04 - accuracy: 0.9999\n",
            "Epoch 96/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5143e-04 - accuracy: 0.9999\n",
            "Epoch 97/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6409e-04 - accuracy: 0.9999\n",
            "Epoch 98/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.2110e-04 - accuracy: 0.9999\n",
            "Epoch 99/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.8330e-04 - accuracy: 0.9999\n",
            "Epoch 100/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.2192e-04 - accuracy: 0.9999\n",
            "Epoch 101/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3558e-04 - accuracy: 0.9999\n",
            "Epoch 102/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3578e-04 - accuracy: 0.9999\n",
            "Epoch 103/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.7808e-04 - accuracy: 0.9999\n",
            "Epoch 104/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.2691e-04 - accuracy: 0.9999\n",
            "Epoch 105/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6338e-04 - accuracy: 0.9999\n",
            "Epoch 106/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.4551e-04 - accuracy: 0.9999\n",
            "Epoch 107/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.3267e-04 - accuracy: 0.9999\n",
            "Epoch 108/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 2.0782e-04 - accuracy: 0.9999\n",
            "Epoch 109/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7916e-04 - accuracy: 0.9999\n",
            "Epoch 110/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 3.8109e-04 - accuracy: 0.9999\n",
            "Epoch 111/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3683e-04 - accuracy: 0.9999\n",
            "Epoch 112/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.1251e-04 - accuracy: 0.9999\n",
            "Epoch 113/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.9824e-04 - accuracy: 0.9999\n",
            "Epoch 114/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.0410e-04 - accuracy: 0.9999\n",
            "Epoch 115/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6789e-04 - accuracy: 0.9999\n",
            "Epoch 116/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.6073e-04 - accuracy: 0.9999\n",
            "Epoch 117/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.0691e-04 - accuracy: 0.9999\n",
            "Epoch 118/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0577e-04 - accuracy: 0.9999\n",
            "Epoch 119/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.6797e-04 - accuracy: 0.9999\n",
            "Epoch 120/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1447e-04 - accuracy: 0.9999\n",
            "Epoch 121/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 3.9723e-04 - accuracy: 0.9999\n",
            "Epoch 122/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1267e-04 - accuracy: 0.9999\n",
            "Epoch 123/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8270e-04 - accuracy: 0.9999\n",
            "Epoch 124/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 1.0023e-04 - accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1882e-04 - accuracy: 0.9999\n",
            "Epoch 126/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 2.0763e-04 - accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.2554e-04 - accuracy: 0.9999\n",
            "Epoch 128/500\n",
            "227845/227845 [==============================] - 7s 30us/step - loss: 3.2448e-04 - accuracy: 0.9999\n",
            "Epoch 129/500\n",
            "227845/227845 [==============================] - 7s 31us/step - loss: 2.9275e-04 - accuracy: 0.9999\n",
            "Epoch 130/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6430e-04 - accuracy: 0.9999\n",
            "Epoch 131/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.1662e-04 - accuracy: 0.9999\n",
            "Epoch 132/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6484e-04 - accuracy: 0.9999\n",
            "Epoch 133/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.6585e-04 - accuracy: 0.9999\n",
            "Epoch 134/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4649e-04 - accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6764e-04 - accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.9140e-04 - accuracy: 0.9999\n",
            "Epoch 137/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7690e-04 - accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7953e-04 - accuracy: 0.9999\n",
            "Epoch 139/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.3040e-04 - accuracy: 0.9999\n",
            "Epoch 140/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3009e-04 - accuracy: 0.9999\n",
            "Epoch 141/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7130e-04 - accuracy: 0.9999\n",
            "Epoch 142/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.2543e-04 - accuracy: 0.9999\n",
            "Epoch 143/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9706e-04 - accuracy: 0.9999\n",
            "Epoch 144/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.4975e-04 - accuracy: 0.9999\n",
            "Epoch 145/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.5606e-04 - accuracy: 0.9999\n",
            "Epoch 146/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 9.1233e-05 - accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.0576e-04 - accuracy: 0.9999\n",
            "Epoch 148/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4928e-04 - accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.9073e-04 - accuracy: 0.9999\n",
            "Epoch 150/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8286e-04 - accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4704e-04 - accuracy: 0.9999\n",
            "Epoch 152/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.4554e-04 - accuracy: 0.9999\n",
            "Epoch 153/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2836e-04 - accuracy: 0.9999\n",
            "Epoch 154/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0963e-04 - accuracy: 0.9999\n",
            "Epoch 155/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8800e-04 - accuracy: 0.9999\n",
            "Epoch 156/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 1.8928e-04 - accuracy: 0.9999\n",
            "Epoch 157/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.7920e-04 - accuracy: 0.9999\n",
            "Epoch 158/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.5658e-04 - accuracy: 0.9999\n",
            "Epoch 159/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0644e-04 - accuracy: 0.9999\n",
            "Epoch 160/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.8903e-04 - accuracy: 0.9999\n",
            "Epoch 161/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4321e-04 - accuracy: 0.9999\n",
            "Epoch 162/500\n",
            "227845/227845 [==============================] - 9s 37us/step - loss: 2.5776e-04 - accuracy: 0.9999\n",
            "Epoch 163/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4721e-04 - accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.9852e-04 - accuracy: 0.9999\n",
            "Epoch 165/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5372e-04 - accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5264e-04 - accuracy: 0.9999\n",
            "Epoch 167/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7654e-04 - accuracy: 0.9999\n",
            "Epoch 168/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.3136e-04 - accuracy: 1.0000\n",
            "Epoch 169/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.8589e-04 - accuracy: 0.9999\n",
            "Epoch 170/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4238e-04 - accuracy: 0.9999\n",
            "Epoch 171/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1011e-04 - accuracy: 1.0000\n",
            "Epoch 172/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.6218e-04 - accuracy: 0.9999\n",
            "Epoch 173/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0730e-04 - accuracy: 1.0000\n",
            "Epoch 174/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2967e-04 - accuracy: 0.9999\n",
            "Epoch 175/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4573e-04 - accuracy: 1.0000\n",
            "Epoch 176/500\n",
            "227845/227845 [==============================] - 7s 30us/step - loss: 3.0410e-04 - accuracy: 0.9999\n",
            "Epoch 177/500\n",
            "227845/227845 [==============================] - 7s 33us/step - loss: 3.1022e-04 - accuracy: 0.9999\n",
            "Epoch 178/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9109e-04 - accuracy: 1.0000\n",
            "Epoch 179/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.0113e-04 - accuracy: 1.0000\n",
            "Epoch 180/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.6969e-04 - accuracy: 0.9999\n",
            "Epoch 181/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.3935e-04 - accuracy: 0.9999\n",
            "Epoch 182/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 9.9248e-05 - accuracy: 1.0000\n",
            "Epoch 183/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4805e-04 - accuracy: 0.9999\n",
            "Epoch 184/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6388e-04 - accuracy: 0.9999\n",
            "Epoch 185/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.0756e-04 - accuracy: 0.9999\n",
            "Epoch 186/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2215e-04 - accuracy: 0.9999\n",
            "Epoch 187/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4970e-04 - accuracy: 0.9999\n",
            "Epoch 188/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.1658e-04 - accuracy: 0.9999\n",
            "Epoch 189/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.0582e-04 - accuracy: 0.9999\n",
            "Epoch 190/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1932e-04 - accuracy: 1.0000\n",
            "Epoch 191/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.1272e-04 - accuracy: 0.9999\n",
            "Epoch 192/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.7041e-04 - accuracy: 0.9999\n",
            "Epoch 193/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3579e-04 - accuracy: 1.0000\n",
            "Epoch 194/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1664e-04 - accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.8947e-04 - accuracy: 0.9999\n",
            "Epoch 196/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.4632e-04 - accuracy: 0.9999\n",
            "Epoch 197/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6327e-04 - accuracy: 0.9999\n",
            "Epoch 198/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.5849e-04 - accuracy: 1.0000\n",
            "Epoch 199/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1190e-04 - accuracy: 1.0000\n",
            "Epoch 200/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.7224e-04 - accuracy: 0.9999\n",
            "Epoch 201/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1143e-04 - accuracy: 1.0000\n",
            "Epoch 202/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6060e-04 - accuracy: 0.9999\n",
            "Epoch 203/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 9.6235e-05 - accuracy: 1.0000\n",
            "Epoch 204/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5799e-04 - accuracy: 0.9999\n",
            "Epoch 205/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2334e-04 - accuracy: 0.9999\n",
            "Epoch 206/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9011e-04 - accuracy: 1.0000\n",
            "Epoch 207/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3942e-04 - accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9261e-04 - accuracy: 0.9999\n",
            "Epoch 209/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.9341e-04 - accuracy: 0.9999\n",
            "Epoch 210/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7865e-04 - accuracy: 1.0000\n",
            "Epoch 211/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4684e-04 - accuracy: 0.9999\n",
            "Epoch 212/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.2454e-04 - accuracy: 0.9999\n",
            "Epoch 213/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4834e-04 - accuracy: 1.0000\n",
            "Epoch 214/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 7.3669e-04 - accuracy: 0.9999\n",
            "Epoch 215/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7659e-04 - accuracy: 0.9999\n",
            "Epoch 216/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6811e-04 - accuracy: 1.0000\n",
            "Epoch 217/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.7915e-04 - accuracy: 1.0000\n",
            "Epoch 218/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.8662e-04 - accuracy: 0.9999\n",
            "Epoch 219/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3173e-04 - accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1371e-04 - accuracy: 1.0000\n",
            "Epoch 221/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.7978e-04 - accuracy: 0.9999\n",
            "Epoch 222/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.2621e-04 - accuracy: 1.0000\n",
            "Epoch 223/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.5775e-04 - accuracy: 0.9999\n",
            "Epoch 224/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.7392e-04 - accuracy: 0.9999\n",
            "Epoch 225/500\n",
            "227845/227845 [==============================] - 8s 35us/step - loss: 2.4767e-04 - accuracy: 1.0000\n",
            "Epoch 226/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 2.0238e-04 - accuracy: 0.9999\n",
            "Epoch 227/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5589e-04 - accuracy: 0.9999\n",
            "Epoch 228/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.7834e-04 - accuracy: 0.9999\n",
            "Epoch 229/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.7025e-04 - accuracy: 1.0000\n",
            "Epoch 230/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8584e-04 - accuracy: 0.9999\n",
            "Epoch 231/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.6460e-04 - accuracy: 0.9999\n",
            "Epoch 232/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5503e-04 - accuracy: 1.0000\n",
            "Epoch 233/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1672e-04 - accuracy: 1.0000\n",
            "Epoch 234/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.7091e-04 - accuracy: 0.9999\n",
            "Epoch 235/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1920e-04 - accuracy: 1.0000\n",
            "Epoch 236/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.3956e-04 - accuracy: 0.9999\n",
            "Epoch 237/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4949e-04 - accuracy: 0.9999\n",
            "Epoch 238/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 9.1933e-05 - accuracy: 1.0000\n",
            "Epoch 239/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0638e-04 - accuracy: 1.0000\n",
            "Epoch 240/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 2.6678e-04 - accuracy: 1.0000\n",
            "Epoch 241/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5020e-04 - accuracy: 1.0000\n",
            "Epoch 242/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0273e-04 - accuracy: 0.9999\n",
            "Epoch 243/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9117e-04 - accuracy: 0.9999\n",
            "Epoch 244/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7939e-04 - accuracy: 1.0000\n",
            "Epoch 245/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5707e-04 - accuracy: 0.9999\n",
            "Epoch 246/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9766e-04 - accuracy: 1.0000\n",
            "Epoch 247/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5476e-04 - accuracy: 1.0000\n",
            "Epoch 248/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.3791e-04 - accuracy: 0.9999\n",
            "Epoch 249/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 9.0460e-05 - accuracy: 1.0000\n",
            "Epoch 250/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.3408e-04 - accuracy: 0.9999\n",
            "Epoch 251/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.2084e-04 - accuracy: 0.9999\n",
            "Epoch 252/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6019e-04 - accuracy: 1.0000\n",
            "Epoch 253/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5556e-04 - accuracy: 1.0000\n",
            "Epoch 254/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2446e-04 - accuracy: 0.9999\n",
            "Epoch 255/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0032e-04 - accuracy: 1.0000\n",
            "Epoch 256/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.2023e-04 - accuracy: 0.9999\n",
            "Epoch 257/500\n",
            "227845/227845 [==============================] - 8s 37us/step - loss: 2.6033e-04 - accuracy: 0.9999\n",
            "Epoch 258/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.7467e-04 - accuracy: 0.9999\n",
            "Epoch 259/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6028e-04 - accuracy: 0.9999\n",
            "Epoch 260/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.3801e-04 - accuracy: 1.0000\n",
            "Epoch 261/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.6083e-04 - accuracy: 0.9999\n",
            "Epoch 262/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7772e-04 - accuracy: 1.0000\n",
            "Epoch 263/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.1150e-04 - accuracy: 0.9999\n",
            "Epoch 264/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4987e-04 - accuracy: 1.0000\n",
            "Epoch 265/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5764e-04 - accuracy: 0.9999\n",
            "Epoch 266/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.8938e-04 - accuracy: 0.9999\n",
            "Epoch 267/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.8625e-04 - accuracy: 1.0000\n",
            "Epoch 268/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.1394e-04 - accuracy: 1.0000\n",
            "Epoch 269/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.5391e-04 - accuracy: 1.0000\n",
            "Epoch 270/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.0242e-04 - accuracy: 1.0000\n",
            "Epoch 271/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9035e-04 - accuracy: 1.0000\n",
            "Epoch 272/500\n",
            "227845/227845 [==============================] - 7s 30us/step - loss: 1.3667e-04 - accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "227845/227845 [==============================] - 7s 32us/step - loss: 3.4438e-04 - accuracy: 0.9999\n",
            "Epoch 274/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 1.9646e-04 - accuracy: 1.0000\n",
            "Epoch 275/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.8454e-04 - accuracy: 0.9999\n",
            "Epoch 276/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8703e-04 - accuracy: 1.0000\n",
            "Epoch 277/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2491e-04 - accuracy: 0.9999\n",
            "Epoch 278/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5923e-04 - accuracy: 0.9999\n",
            "Epoch 279/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7117e-04 - accuracy: 1.0000\n",
            "Epoch 280/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7821e-04 - accuracy: 0.9999\n",
            "Epoch 281/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5182e-04 - accuracy: 1.0000\n",
            "Epoch 282/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.7007e-04 - accuracy: 1.0000\n",
            "Epoch 283/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.3972e-04 - accuracy: 0.9999\n",
            "Epoch 284/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4210e-04 - accuracy: 0.9999\n",
            "Epoch 285/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4811e-04 - accuracy: 1.0000\n",
            "Epoch 286/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 2.1306e-04 - accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2110e-04 - accuracy: 1.0000\n",
            "Epoch 288/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.7832e-04 - accuracy: 1.0000\n",
            "Epoch 289/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5999e-04 - accuracy: 1.0000\n",
            "Epoch 290/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.7953e-04 - accuracy: 1.0000\n",
            "Epoch 291/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8847e-04 - accuracy: 1.0000\n",
            "Epoch 292/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 1.5011e-04 - accuracy: 1.0000\n",
            "Epoch 293/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5618e-04 - accuracy: 1.0000\n",
            "Epoch 294/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.2686e-04 - accuracy: 1.0000\n",
            "Epoch 295/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8710e-04 - accuracy: 1.0000\n",
            "Epoch 296/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6294e-04 - accuracy: 0.9999\n",
            "Epoch 297/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4041e-04 - accuracy: 1.0000\n",
            "Epoch 298/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3881e-04 - accuracy: 1.0000\n",
            "Epoch 299/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 8.7696e-05 - accuracy: 1.0000\n",
            "Epoch 300/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.3912e-04 - accuracy: 1.0000\n",
            "Epoch 301/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.9388e-04 - accuracy: 1.0000\n",
            "Epoch 302/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.1119e-04 - accuracy: 0.9999\n",
            "Epoch 303/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.8946e-04 - accuracy: 0.9999\n",
            "Epoch 304/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.0515e-04 - accuracy: 1.0000\n",
            "Epoch 305/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.7260e-04 - accuracy: 0.9999\n",
            "Epoch 306/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5055e-04 - accuracy: 1.0000\n",
            "Epoch 307/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.5799e-04 - accuracy: 1.0000\n",
            "Epoch 308/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.0088e-04 - accuracy: 0.9999\n",
            "Epoch 309/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8371e-04 - accuracy: 1.0000\n",
            "Epoch 310/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.2695e-04 - accuracy: 1.0000\n",
            "Epoch 311/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.6350e-04 - accuracy: 1.0000\n",
            "Epoch 312/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.2068e-04 - accuracy: 1.0000\n",
            "Epoch 313/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2365e-04 - accuracy: 1.0000\n",
            "Epoch 314/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.6049e-04 - accuracy: 0.9999\n",
            "Epoch 315/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3170e-04 - accuracy: 1.0000\n",
            "Epoch 316/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3450e-04 - accuracy: 1.0000\n",
            "Epoch 317/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0887e-04 - accuracy: 1.0000\n",
            "Epoch 318/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2521e-04 - accuracy: 1.0000\n",
            "Epoch 319/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 2.1750e-04 - accuracy: 0.9999\n",
            "Epoch 320/500\n",
            "227845/227845 [==============================] - 7s 32us/step - loss: 8.1066e-05 - accuracy: 1.0000\n",
            "Epoch 321/500\n",
            "227845/227845 [==============================] - 7s 30us/step - loss: 3.5896e-04 - accuracy: 0.9999\n",
            "Epoch 322/500\n",
            "227845/227845 [==============================] - 7s 30us/step - loss: 7.1793e-05 - accuracy: 1.0000\n",
            "Epoch 323/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4635e-04 - accuracy: 0.9999\n",
            "Epoch 324/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.9874e-04 - accuracy: 1.0000\n",
            "Epoch 325/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.7430e-04 - accuracy: 1.0000\n",
            "Epoch 326/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 2.2750e-04 - accuracy: 0.9999\n",
            "Epoch 327/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.3971e-04 - accuracy: 1.0000\n",
            "Epoch 328/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4354e-04 - accuracy: 1.0000\n",
            "Epoch 329/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5625e-04 - accuracy: 1.0000\n",
            "Epoch 330/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 2.6212e-04 - accuracy: 0.9999\n",
            "Epoch 331/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1939e-04 - accuracy: 1.0000\n",
            "Epoch 332/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 3.8689e-04 - accuracy: 0.9999\n",
            "Epoch 333/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 1.3102e-04 - accuracy: 1.0000\n",
            "Epoch 334/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2953e-04 - accuracy: 0.9999\n",
            "Epoch 335/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9355e-04 - accuracy: 1.0000\n",
            "Epoch 336/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 3.7388e-04 - accuracy: 1.0000\n",
            "Epoch 337/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.0343e-04 - accuracy: 1.0000\n",
            "Epoch 338/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4152e-04 - accuracy: 1.0000\n",
            "Epoch 339/500\n",
            "227845/227845 [==============================] - 6s 29us/step - loss: 1.7982e-04 - accuracy: 1.0000\n",
            "Epoch 340/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.6508e-04 - accuracy: 0.9999\n",
            "Epoch 341/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6089e-04 - accuracy: 1.0000\n",
            "Epoch 342/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.2555e-04 - accuracy: 1.0000\n",
            "Epoch 343/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6889e-04 - accuracy: 1.0000\n",
            "Epoch 344/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1617e-04 - accuracy: 1.0000\n",
            "Epoch 345/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.8873e-04 - accuracy: 0.9999\n",
            "Epoch 346/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1689e-04 - accuracy: 1.0000\n",
            "Epoch 347/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.1929e-04 - accuracy: 1.0000\n",
            "Epoch 348/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 7.7862e-05 - accuracy: 1.0000\n",
            "Epoch 349/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8975e-04 - accuracy: 1.0000\n",
            "Epoch 350/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4449e-04 - accuracy: 1.0000\n",
            "Epoch 351/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5209e-04 - accuracy: 1.0000\n",
            "Epoch 352/500\n",
            "227845/227845 [==============================] - 9s 41us/step - loss: 9.2748e-05 - accuracy: 1.0000\n",
            "Epoch 353/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.3058e-04 - accuracy: 1.0000\n",
            "Epoch 354/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.2869e-04 - accuracy: 1.0000\n",
            "Epoch 355/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9982e-04 - accuracy: 1.0000\n",
            "Epoch 356/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1796e-04 - accuracy: 1.0000\n",
            "Epoch 357/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.0593e-04 - accuracy: 1.0000\n",
            "Epoch 358/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.1416e-04 - accuracy: 1.0000\n",
            "Epoch 359/500\n",
            "227845/227845 [==============================] - 6s 29us/step - loss: 1.0357e-04 - accuracy: 1.0000\n",
            "Epoch 360/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.3329e-04 - accuracy: 1.0000\n",
            "Epoch 361/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.5625e-04 - accuracy: 1.0000\n",
            "Epoch 362/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 7.6329e-05 - accuracy: 1.0000\n",
            "Epoch 363/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.0228e-04 - accuracy: 1.0000\n",
            "Epoch 364/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 8.9861e-05 - accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.6564e-04 - accuracy: 0.9999\n",
            "Epoch 366/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.8944e-04 - accuracy: 0.9999\n",
            "Epoch 367/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.8444e-04 - accuracy: 1.0000\n",
            "Epoch 368/500\n",
            "227845/227845 [==============================] - 7s 31us/step - loss: 1.5809e-04 - accuracy: 1.0000\n",
            "Epoch 369/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.6499e-04 - accuracy: 0.9999\n",
            "Epoch 370/500\n",
            "227845/227845 [==============================] - 7s 30us/step - loss: 1.1780e-04 - accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 1.7673e-04 - accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.3950e-04 - accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5989e-04 - accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 9.0407e-05 - accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5805e-04 - accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.0476e-04 - accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0401e-04 - accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.9705e-04 - accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.0334e-04 - accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "227845/227845 [==============================] - 7s 29us/step - loss: 3.0805e-04 - accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9968e-04 - accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.5936e-04 - accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6795e-04 - accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.8766e-04 - accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0432e-04 - accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 7.3066e-05 - accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.4936e-04 - accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.1190e-04 - accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.2169e-04 - accuracy: 0.9999\n",
            "Epoch 390/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.4621e-04 - accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.2548e-04 - accuracy: 0.9999\n",
            "Epoch 392/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6426e-04 - accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9052e-04 - accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.6911e-04 - accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.0316e-04 - accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.5159e-04 - accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 1.8062e-04 - accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 2.6162e-04 - accuracy: 0.9999\n",
            "Epoch 399/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9591e-04 - accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.9320e-04 - accuracy: 0.9999\n",
            "Epoch 401/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.2198e-04 - accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 8.5292e-05 - accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.1136e-04 - accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 1.3150e-04 - accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 2.1729e-04 - accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "227845/227845 [==============================] - 6s 27us/step - loss: 2.6623e-04 - accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.0345e-04 - accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 3.9708e-04 - accuracy: 0.9999\n",
            "Epoch 409/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 6.8055e-05 - accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 5.3583e-05 - accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 4.0922e-04 - accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.3910e-04 - accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.0023e-04 - accuracy: 1.0000\n",
            "Epoch 414/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 2.1631e-04 - accuracy: 1.0000\n",
            "Epoch 415/500\n",
            "227845/227845 [==============================] - 6s 28us/step - loss: 1.2645e-04 - accuracy: 1.0000\n",
            "Epoch 416/500\n",
            " 50450/227845 [=====>........................] - ETA: 5s - loss: 7.5540e-06 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHUL8pr4vAP"
      },
      "source": [
        "ANN_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u04SG82WkJe9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsowuHe0kGpH"
      },
      "source": [
        "\n",
        "#Array of list of list to Array of list\n",
        "Y_new = []\n",
        "for i in Y_pred:\n",
        "  for k in i:\n",
        "    Y_new.append(str(int(k)))\n",
        "  \n",
        "Y_new = np.array(Y_new, dtype = object) \n",
        "\n",
        "#PRINT\n",
        "#Y_test, Y_new\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, Y_new)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni4o6y-a462j"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, Y_new))\n",
        "print(classification_report(Y_test, Y_new))\n",
        "\n",
        "\"\"\"\n",
        "CASE 1: \n",
        "Layer 1 : unit = 10\n",
        "Layer 2 : unit = 5\n",
        "Layer 3 : unit = 1\n",
        "Batch_size = 10, nb_epoch = 100\n",
        "Accuracy score 0.0.859649\n",
        "\n",
        "CASE 2: \n",
        "Layer 1 : unit = 30\n",
        "Layer 2 : unit = 15\n",
        "Layer 3 : unit = 1\n",
        "Batch_size = 10, nb_epoch = 100\n",
        "Accuracy score 0.956140\n",
        "\n",
        "CASE 3: \n",
        "Layer 1 : unit = 30\n",
        "Layer 2 : unit = 15\n",
        "Layer 3 : unit = 1\n",
        "Batch_size = 15, nb_epoch = 100\n",
        "Accuracy score 0.964912 \n",
        "\n",
        "CASE 4: \n",
        "Layer 1 : unit = 30\n",
        "Layer 2 : unit = 15\n",
        "Layer 3 : unit = 1\n",
        "Batch_size = 30, nb_epoch = 100\n",
        "Accuracy score 0.964912 \n",
        "\n",
        "CASE 5: \n",
        "Layer 1 : unit = 30\n",
        "Layer 2 : unit = 15\n",
        "Layer 3 : unit = 1\n",
        "Batch_size = 30, nb_epoch = 1000\n",
        "Accuracy score 0.964912 \n",
        "\n",
        "CASE 6: \n",
        "Layer 1 : unit = 30\n",
        "Layer 2 : unit = 20\n",
        "Layer 3 : unit = 10\n",
        "Layer 4 : unit = 1\n",
        "Batch_size = 30, nb_epoch = 100\n",
        "Accuracy score 0.964912 \n",
        "\n",
        "CASE 7:\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 30, activation = 'relu', input_shape=(30,)))\n",
        "model.add(Dense(units = 15, activation = 'relu'))\n",
        "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size = 30, nb_epoch = 1000)\n",
        "\n",
        "Accuracy score 0.973684\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.96      1.00      0.98        75\n",
        "           1       1.00      0.92      0.96        39\n",
        "\n",
        "    accuracy                           0.97       114\n",
        "   macro avg       0.98      0.96      0.97       114\n",
        "weighted avg       0.97      0.97      0.97       114\n",
        "\n",
        "CASE 8:\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 30, activation = 'relu', input_shape=(30,)))\n",
        "model.add(Dense(units = 15, activation = 'relu'))\n",
        "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size = 30, nb_epoch = 1000)\n",
        "\n",
        "\n",
        "Accuracy score 0.982456\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      1.00      0.99        75\n",
        "           1       1.00      0.95      0.97        39\n",
        "\n",
        "    accuracy                           0.98       114\n",
        "   macro avg       0.99      0.97      0.98       114\n",
        "weighted avg       0.98      0.98      0.98       114\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCe7Zf9HBcoW"
      },
      "source": [
        "************************************************************************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2qB1D_KtmhL"
      },
      "source": [
        "#Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-7h-3vgu35t"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ8Y3WN_oOV3"
      },
      "source": [
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test =sc_X.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCU8dMUku33L"
      },
      "source": [
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(units = 455, activation = 'relu', input_shape=(30,)))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(1000, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(500, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(100, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(10, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='sigmoid'))\n",
        "/\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAsMvoECgG55"
      },
      "source": [
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='weights.best.cnn.hdf5', verbose=1, save_best_only=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylj52TFRwPjt"
      },
      "source": [
        "Y = df['Class'].values\n",
        "X = df.drop('Class', axis=1).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPVn9qXKu3vz"
      },
      "source": [
        "NN_model.fit(X_train, Y_train, epochs=1000, batch_size=50, validation_split = 0.2, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2mUOEtB2dac"
      },
      "source": [
        "#NN_model.load_weights('weights.best.cnn.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi2v5_e2u3tt"
      },
      "source": [
        "#wights_file = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "#NN_model.load_weights(wights_file) \n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLFsCAkUu3oS"
      },
      "source": [
        "DL_pred = model.predict(X_test)\n",
        "\n",
        "#Array of list of list to Array of list\n",
        "DLPred = []\n",
        "for i in DL_pred:\n",
        "  for k in i:\n",
        "    DLPred.append(str(int(k)))\n",
        "  \n",
        "DLPred = np.array(DLPred, dtype = object) \n",
        "\n",
        "#PRINT\n",
        "#Y_test, Y_new\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, DLPred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxsi0GnLrP3d"
      },
      "source": [
        "print(\"Accuracy score %f\" % accuracy_score(Y_test, DLPred))\n",
        "print(classification_report(Y_test, DLPred))\n",
        "\n",
        "\"\"\"\n",
        "CASE 1:\n",
        "#The Input Later\n",
        "NN_model.add(Dense(units = 100, activation = 'relu', input_shape=(30,)))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(50, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(10, kernel_initializer='normal',activation='relu'))\n",
        "#NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='sigmoid'))\n",
        "\n",
        "#RESULT: \n",
        "Epoch 00500: val_loss did not improve from 0.00001\n",
        "Accuracy score 0.964912\n",
        "\n",
        "CASE 2:\n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(units = 455, activation = 'relu', input_shape=(30,)))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(200, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(100, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(50, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='sigmoid'))\n",
        "/\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "NN_model.summary()\n",
        "\n",
        "NN_model.fit(X_train, Y_train, epochs=1000, batch_size=30, validation_split = 0.2, callbacks=callbacks_list)\n",
        "\n",
        "Accuracy score 0.973684\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.96      1.00      0.98        75\n",
        "           1       1.00      0.92      0.96        39\n",
        "\n",
        "    accuracy                           0.97       114\n",
        "   macro avg       0.98      0.96      0.97       114\n",
        "weighted avg       0.97      0.97      0.97       114\n",
        "\n",
        "CASE 3:\n",
        "\n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(units = 455, activation = 'relu', input_shape=(30,)))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(200, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(100, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(50, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='sigmoid'))\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "NN_model.summary()\n",
        "\n",
        "NN_model.fit(X_train, Y_train, epochs=1000, batch_size=30, validation_split = 0.2, callbacks=callbacks_list)\n",
        "\n",
        "Epoch 01000: val_loss did not improve from 0.00000\n",
        "\n",
        "Accuracy score 0.982456\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      1.00      0.99        75\n",
        "           1       1.00      0.95      0.97        39\n",
        "\n",
        "    accuracy                           0.98       114\n",
        "   macro avg       0.99      0.97      0.98       114\n",
        "weighted avg       0.98      0.98      0.98       114\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlq3lo1TIZOy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fEBQvJAIZKc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}